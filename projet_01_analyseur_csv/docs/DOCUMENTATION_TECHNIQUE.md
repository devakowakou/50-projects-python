# üìö Documentation Technique - Analyseur CSV Professionnel

## üèóÔ∏è Architecture D√©taill√©e

### Principes de Conception

L'application suit le principe de **Separation of Concerns (SoC)** avec une architecture modulaire o√π chaque module a une responsabilit√© unique et bien d√©finie.

### Modules et Responsabilit√©s

#### 1. `data_loader.py` - Chargement des Donn√©es
**Responsabilit√©**: Charger et valider les fichiers CSV/Excel

**Classe principale**: `DataLoader`

**M√©thodes cl√©s**:
- `detect_encoding()` : D√©tecte automatiquement l'encodage du fichier
- `load_from_upload()` : Charge depuis l'upload Streamlit
- `load_from_path()` : Charge depuis un chemin de fichier
- `validate_data()` : Valide la structure et la qualit√©
- `get_column_types()` : Identifie les types de colonnes

**Technologies**: pandas, chardet, io

---

#### 2. `data_cleaner.py` - Nettoyage des Donn√©es
**Responsabilit√©**: Pr√©traiter et nettoyer les donn√©es

**Classe principale**: `DataCleaner`

**M√©thodes cl√©s**:
- `get_missing_values_summary()` : R√©sum√© des valeurs manquantes
- `handle_missing_values()` : Traite les NaN (5 strat√©gies)
- `remove_duplicates()` : Supprime les doublons
- `convert_column_type()` : Convertit les types
- `normalize_column_names()` : Normalise les noms
- `remove_outliers_iqr()` : Supprime les outliers
- `get_data_quality_report()` : Rapport de qualit√©

**Strat√©gies d'imputation**:
1. Drop : Suppression des lignes
2. Mean : Remplacement par la moyenne
3. Median : Remplacement par la m√©diane
4. Mode : Remplacement par le mode
5. Custom : Valeur personnalis√©e

---

#### 3. `statistical_analyzer.py` - Analyses Statistiques
**Responsabilit√©**: Calculer toutes les statistiques descriptives

**Classe principale**: `StatisticalAnalyzer`

**M√©thodes cl√©s**:
- `get_basic_statistics()` : Stats de base (mean, std, quartiles...)
- `get_advanced_statistics()` : Stats avanc√©es (skewness, kurtosis...)
- `get_distribution_analysis()` : Tests de normalit√©
- `get_frequency_analysis()` : Analyse de fr√©quence
- `get_percentiles()` : Calcul de percentiles personnalis√©s
- `get_summary_by_category()` : Stats group√©es

**Tests statistiques**:
- Shapiro-Wilk (normalit√©, n < 5000)
- Kolmogorov-Smirnov (normalit√©, tout n)

---

#### 4. `correlation_analyzer.py` - Analyse de Corr√©lation
**Responsabilit√©**: Analyser les relations entre variables

**Classe principale**: `CorrelationAnalyzer`

**M√©thodes cl√©s**:
- `get_correlation_matrix()` : Matrice compl√®te
- `get_correlation_pairs()` : Paires fortement corr√©l√©es
- `test_correlation_significance()` : Tests statistiques
- `get_top_correlations()` : Top N corr√©lations
- `detect_multicollinearity()` : D√©tection de multicolin√©arit√©
- `calculate_partial_correlation()` : Corr√©lation partielle

**M√©thodes de corr√©lation**:
1. **Pearson** : Corr√©lation lin√©aire (r)
   - Mesure la relation lin√©aire
   - Sensible aux outliers
   - Assume normalit√©

2. **Spearman** : Corr√©lation de rang (œÅ)
   - Non-param√©trique
   - D√©tecte relations monotones
   - R√©sistant aux outliers

3. **Kendall** : Tau de Kendall (œÑ)
   - Non-param√©trique
   - Bas√© sur concordance
   - Pr√©f√©r√© pour petits √©chantillons

**Interpr√©tation**:
- |r| ‚â• 0.9 : Tr√®s forte
- |r| ‚â• 0.7 : Forte
- |r| ‚â• 0.5 : Mod√©r√©e
- |r| ‚â• 0.3 : Faible
- |r| < 0.3 : Tr√®s faible

---

#### 5. `anomaly_detector.py` - D√©tection d'Anomalies
**Responsabilit√©**: Identifier les valeurs aberrantes

**Classe principale**: `AnomalyDetector`

**M√©thodes cl√©s**:
- `detect_outliers_iqr()` : M√©thode IQR
- `detect_outliers_zscore()` : M√©thode Z-Score
- `detect_outliers_all_columns()` : D√©tection globale
- `get_multivariate_outliers()` : Mahalanobis
- `compare_methods()` : Comparaison des m√©thodes
- `suggest_treatment()` : Suggestions de traitement

**M√©thode IQR (Interquartile Range)**:
```
Q1 = 25e percentile
Q3 = 75e percentile
IQR = Q3 - Q1

Outliers si:
  x < Q1 - 1.5√óIQR  OU  x > Q3 + 1.5√óIQR
  
Outliers extr√™mes si:
  x < Q1 - 3√óIQR  OU  x > Q3 + 3√óIQR
```

**M√©thode Z-Score**:
```
z = (x - Œº) / œÉ

Outlier si: |z| > 3
```

**Distance de Mahalanobis** (multivari√©):
```
D¬≤ = (x - Œº)·µÄ Œ£‚Åª¬π (x - Œº)

Outlier si: D¬≤ > œá¬≤(p, 0.95)
```

---

#### 6. `visualizer.py` - Visualisations
**Responsabilit√©**: Cr√©er tous les graphiques interactifs

**Classe principale**: `Visualizer`

**M√©thodes cl√©s**:
- `create_histogram()` : Distribution avec courbe normale
- `create_boxplot()` : Box plots pour outliers
- `create_correlation_heatmap()` : Heatmap de corr√©lation
- `create_scatter_plot()` : Scatter avec tendance
- `create_bar_chart()` : Fr√©quences cat√©goriques
- `create_pie_chart()` : R√©partition en camembert
- `create_violin_plot()` : Distribution d√©taill√©e
- `create_missing_values_chart()` : Visualisation des NaN

**Technologies**: Plotly (graphiques interactifs)

**Avantages de Plotly**:
- Interactivit√© (zoom, hover, s√©lection)
- Responsive design
- Export PNG/SVG
- Th√®mes personnalisables

---

#### 7. `report_generator.py` - G√©n√©ration de Rapports
**Responsabilit√©**: Exporter les r√©sultats

**Classe principale**: `ReportGenerator`

**M√©thodes cl√©s**:
- `export_to_csv()` : Export CSV
- `export_statistics_to_json()` : Stats en JSON
- `generate_markdown_report()` : Rapport format√©
- `export_cleaned_data()` : Donn√©es nettoy√©es
- `create_excel_report()` : Rapport Excel multi-feuilles

**Formats support√©s**:
- CSV (donn√©es)
- JSON (statistiques)
- Markdown (rapport lisible)
- Excel (rapport complet)

---

### Flux de Donn√©es

```
1. Upload CSV
   ‚Üì
2. DataLoader ‚Üí Validation
   ‚Üì
3. DataCleaner ‚Üí Nettoyage (optionnel)
   ‚Üì
4. Analyse parall√®le:
   ‚îú‚îÄ StatisticalAnalyzer ‚Üí Statistiques
   ‚îú‚îÄ CorrelationAnalyzer ‚Üí Corr√©lations
   ‚îî‚îÄ AnomalyDetector ‚Üí Anomalies
   ‚Üì
5. Visualizer ‚Üí Graphiques
   ‚Üì
6. ReportGenerator ‚Üí Export
```

---

## üé® Interface Streamlit

### Structure de l'Application

**Sidebar**:
- Configuration
- Upload de fichiers
- M√©tadonn√©es du fichier

**Main Content (Tabs)**:
1. Aper√ßu : Vue d'ensemble
2. Nettoyage : Traitement des donn√©es
3. Statistiques : Analyses descriptives
4. Corr√©lations : Relations entre variables
5. Anomalies : D√©tection d'outliers
6. Visualisations : Graphiques interactifs
7. Rapports : Export des r√©sultats

### Session State

Variables de session Streamlit:
- `df` : DataFrame original
- `df_cleaned` : DataFrame nettoy√©
- `file_info` : M√©tadonn√©es du fichier

---

## üîß Configuration (`config.py`)

### Param√®tres Modifiables

**Application**:
- `APP_TITLE` : Titre de l'app
- `APP_LAYOUT` : "wide" ou "centered"
- `MAX_FILE_SIZE_MB` : Taille max des fichiers

**Statistiques**:
- `CONFIDENCE_LEVEL` : Niveau de confiance (d√©faut: 0.95)
- `IQR_MULTIPLIER` : Multiplicateur IQR (d√©faut: 1.5)
- `Z_SCORE_THRESHOLD` : Seuil Z-Score (d√©faut: 3)

**Corr√©lation**:
- `CORRELATION_THRESHOLD` : Seuil significatif (d√©faut: 0.7)

**Visualisation**:
- `PLOTLY_THEME` : Th√®me Plotly
- `COLOR_PALETTE` : Palette de couleurs

---

## üìä Cas d'Usage

### 1. Analyse de Ventes
```python
# Charger les donn√©es
# Statistiques par r√©gion, par produit
# Corr√©lations prix-quantit√©
# D√©tection de ventes anormales
```

### 2. Contr√¥le Qualit√©
```python
# Charger mesures de production
# Identifier les outliers
# Analyser la distribution
# G√©n√©rer rapport de conformit√©
```

### 3. Analyse de Marketing
```python
# Donn√©es de campagnes
# Corr√©lations budget-conversions
# Identifier segments performants
# Visualiser KPIs
```

---

## üß™ Tests et Validation

### Tests Manuels

1. **Test de Chargement**
   - Fichier vide
   - Encodage incorrect
   - Format non support√©
   - Fichier tr√®s volumineux

2. **Test de Nettoyage**
   - 100% valeurs manquantes
   - Aucune valeur manquante
   - Tous duplicatas

3. **Test de Statistiques**
   - Aucune colonne num√©rique
   - Distribution normale
   - Distribution asym√©trique

4. **Test de Corr√©lation**
   - Moins de 2 colonnes num√©riques
   - Corr√©lation parfaite (1.0)
   - Aucune corr√©lation

---

## üöÄ Optimisations Futures

### Performance
- [ ] Lazy loading pour gros fichiers
- [ ] Cache des calculs lourds
- [ ] Parall√©lisation des analyses

### Fonctionnalit√©s
- [ ] Analyse de s√©ries temporelles
- [ ] Machine Learning (clustering, PCA)
- [ ] Support de bases de donn√©es
- [ ] API REST

### UX/UI
- [ ] Mode sombre
- [ ] Templates de rapports
- [ ] Comparaison de datasets
- [ ] Historique des analyses

---

## üìö R√©f√©rences

### Documentation
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)
- [SciPy Stats](https://docs.scipy.org/doc/scipy/reference/stats.html)
- [Plotly Python](https://plotly.com/python/)
- [Streamlit API](https://docs.streamlit.io/library/api-reference)

### Concepts Statistiques
- Tests de normalit√©
- Corr√©lation vs Causalit√©
- D√©tection d'outliers
- Intervalles de confiance

---

**Derni√®re mise √† jour**: 2025-10-27
