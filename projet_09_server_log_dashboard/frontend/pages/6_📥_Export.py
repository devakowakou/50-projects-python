import streamlit as st
import pandas as pd
from datetime import datetime
import sys
from pathlib import Path
import json
from io import StringIO

sys.path.append(str(Path(__file__).parent.parent))

from utils.api_client import APIClient

st.set_page_config(page_title="Export de Rapports", page_icon="üì•", layout="wide")

st.title("üì• Export de Rapports")

api = APIClient()

st.info("üìä Exportez vos analyses en format CSV/JSON pour traitement externe (sans limite de volume)")

col1, col2 = st.columns(2)

with col1:
    hours = st.number_input("P√©riode (heures)", 1, 720, 24, help="Max 30 jours (720h)")

with col2:
    export_format = st.selectbox("Format", ["CSV", "JSON"])

if st.button("üöÄ G√©n√©rer le rapport", type="primary"):
    with st.spinner("üì¶ G√©n√©ration en cours..."):
        try:
            # Appeler l'API d'export
            data = api.export_logs(hours=hours, format=export_format.lower())
            
            if export_format == "CSV":
                # data est d√©j√† le contenu CSV
                filename = f"rapport_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                
                st.download_button(
                    label="‚¨áÔ∏è T√©l√©charger le rapport CSV",
                    data=data,
                    file_name=filename,
                    mime="text/csv"
                )
                
                # Compter les lignes
                lines = data.strip().split('\n')
                total = len(lines) - 1  # -1 pour le header
                
                st.success(f"‚úÖ {total:,} logs export√©s avec succ√®s !")
                
                # Preview
                st.subheader("üëÄ Aper√ßu des donn√©es (20 premi√®res lignes)")
                df = pd.read_csv(StringIO(data))
                st.dataframe(df.head(20), use_container_width=True)
                
                # Stats rapides
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("Total lignes", f"{len(df):,}")
                with col_b:
                    st.metric("IPs uniques", f"{df['ip'].nunique():,}")
                with col_c:
                    st.metric("P√©riode", f"{hours}h")
            
            else:  # JSON
                # data est un dict
                json_str = json.dumps(data, indent=2)
                filename = f"rapport_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                
                st.download_button(
                    label="‚¨áÔ∏è T√©l√©charger le rapport JSON",
                    data=json_str,
                    file_name=filename,
                    mime="application/json"
                )
                
                st.success(f"‚úÖ {data['total']:,} logs export√©s avec succ√®s !")
                
                # M√©tadonn√©es
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("Total logs", f"{data['total']:,}")
                with col_b:
                    st.metric("P√©riode", f"{data['period_hours']}h")
                with col_c:
                    st.metric("Date export", data['export_date'][:10])
                
                # Preview JSON (5 premiers logs)
                st.subheader("üëÄ Aper√ßu JSON (5 premiers logs)")
                st.json(data['logs'][:5])
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'export: {e}")
            st.exception(e)

st.markdown("---")

st.markdown("""
### üìã Informations sur l'export

- **CSV** : Format tabulaire, id√©al pour Excel/Pandas
- **JSON** : Format structur√©, id√©al pour API/scripts
- **Volume** : Aucune limite stricte, tous les logs de la p√©riode
- **Performance** : Optimis√© pour gros volumes via requ√™tes SQL directes

### üí° Cas d'usage

1. **Analyse externe** : Import dans Excel, Tableau, Power BI
2. **Archivage** : Sauvegarde p√©riodique des logs
3. **Machine Learning** : Datasets pour entra√Ænement de mod√®les
4. **Audit** : G√©n√©ration de rapports de conformit√©
""")
